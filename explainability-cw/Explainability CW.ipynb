{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4907a9b-7f61-4e03-a118-3ca33156b516",
   "metadata": {},
   "source": [
    "# Ethics, Fairness and Explanation in AI Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18977034-9183-47c7-993e-9b105ebaf8bc",
   "metadata": {},
   "source": [
    "Your goal in this coursework is to implement and experiment with various explainability approaches in order to better understand the behaviour of a neural model applied to the Titanic dataset. As you will have a chance to observe, the dataset reflects some of the past social conventions and biases, which also affect the trained model. Explanations can serve as very useful tools for identifying such potential issues and gaining insight into the internal reasoning of machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54e2fe-cc8f-4b0d-852a-474e43b5b060",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f683e86-6c7d-4ce1-9cc9-a3ec171824d8",
   "metadata": {},
   "source": [
    "We start by defining some helpful utility functions for data preprocessing. You will probably not need to change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3853c0d-4ab5-41dc-a409-ef3b7dab0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class InvertibleColumnTransformer(ColumnTransformer):\n",
    "    \"\"\"\n",
    "    This is an invertible version of a ColumnTransformer from sklearn.\n",
    "    This allows us to recover the original feature values from their normalised\n",
    "    versions in order to better understand the produced explanations.\n",
    "    \"\"\"\n",
    "    def inverse_transform(self, X):\n",
    "        if X.ndim == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        if X.shape[1] != len(self.get_feature_names_out()):\n",
    "            raise ValueError(\n",
    "                \"X and the fitted transformer have different numbers of columns\"\n",
    "            )\n",
    "\n",
    "        inverted_X_base = np.zeros((X.shape[0], self.n_features_in_))\n",
    "        columns = [c for cs in self._columns for c in cs]\n",
    "        inverted_X = pd.DataFrame(data=inverted_X_base, columns=columns)\n",
    "        inverted_X = inverted_X.astype('object')\n",
    "        for name, indices in self.output_indices_.items():\n",
    "            transformer = self.named_transformers_.get(name, None)\n",
    "            if transformer is None:\n",
    "                continue\n",
    "\n",
    "            selected_X = X[:, indices.start : indices.stop]\n",
    "            if isinstance(transformer, OneHotEncoder):\n",
    "                # Assumed only one column changing encoder at the end\n",
    "                categories = transformer.inverse_transform(selected_X)\n",
    "                inverted_X.loc[\n",
    "                    :, columns[indices.start : indices.start + len(categories[0])]\n",
    "                ] = categories\n",
    "            else:\n",
    "                # Assumed scaler-type transformer\n",
    "                inverted_X.loc[\n",
    "                    :, [columns[i] for i in range(indices.start, indices.stop)]\n",
    "                ] = transformer.inverse_transform(selected_X)\n",
    "\n",
    "        return inverted_X\n",
    "\n",
    "\n",
    "def preprocess_train_data(\n",
    "    df,\n",
    "    scaled_features=None,\n",
    "    categorical_features=None,\n",
    "    scaler=RobustScaler(quantile_range=(10, 90)),\n",
    "    categorical_encoder=OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Scales the continuous features using a RobustScaler and one-hot encodes\n",
    "    the categorical features.\n",
    "    \"\"\"\n",
    "    if scaled_features is None and categorical_features is None:\n",
    "        warnings.warn(\"No features specified for preprocessing, using raw data.\")\n",
    "        scaled_features = []\n",
    "        categorical_features = []\n",
    "    elif scaled_features is None:\n",
    "        scaled_features = [c for c in df.columns if c not in categorical_features]\n",
    "    elif categorical_features is None:\n",
    "        categorical_features = [c for c in df.columns if c not in scaled_features]\n",
    "\n",
    "    preprocessor = InvertibleColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", scaler, scaled_features),\n",
    "            (\"cat\", categorical_encoder, categorical_features),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    preprocessed_df = preprocessor.fit_transform(df)\n",
    "    return preprocessed_df, preprocessor\n",
    "\n",
    "\n",
    "def preprocess_test_data(df, preprocessor):\n",
    "    preprocessed_df = preprocessor.transform(df)\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35c3a2-09c0-4a14-9f83-e81db1d544a1",
   "metadata": {},
   "source": [
    "Here, we define a class for the Titanic dataset, which we will be using throughout the coursework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22f7f44d-1cbe-4e25-9f7c-7bbe8c2d4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TitanicDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the Titanic dataset.\n",
    "    \"\"\"\n",
    "    __create_key = object()\n",
    "\n",
    "    @classmethod\n",
    "    def create_datasets(\n",
    "        cls,\n",
    "        label_name=\"survived\",\n",
    "        split_seed=42,\n",
    "        test_size=0.2,\n",
    "    ):\n",
    "        train_dataset = TitanicDataset(\n",
    "            cls.__create_key,\n",
    "            label_name=label_name,\n",
    "            split_seed=split_seed,\n",
    "            test_size=test_size,\n",
    "            train=True,\n",
    "        )\n",
    "        test_dataset = TitanicDataset(\n",
    "            cls.__create_key,\n",
    "            label_name=label_name,\n",
    "            split_seed=split_seed,\n",
    "            test_size=test_size,\n",
    "            train=False,\n",
    "        )\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        create_key=None,\n",
    "        label_name=\"Survived\",\n",
    "        split_seed=42,\n",
    "        test_size=0.2,\n",
    "        train=True,\n",
    "    ):\n",
    "        # Ensure that the dataset is being constructed properly\n",
    "        if create_key != TitanicDataset.__create_key:\n",
    "            raise ValueError(\n",
    "                \"Illegal initialisation attempt — please use create_datasets to initialise.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            data_df = pd.read_csv(\"titanic-dataset.csv\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"Titanic data file not found.\")\n",
    "\n",
    "        # Split the dataset into train and test\n",
    "        x = data_df.drop(columns=[label_name, \"name\", \"ticket\", \"cabin\", \"embarked\", \"boat\", \"body\", \"home.dest\"])\n",
    "        # For the purposes of this coursework, we just impute the missing age and fare with a median value\n",
    "        x[['age']] = x[['age']].fillna(x[['age']].median())\n",
    "        x[['fare']] = x[['fare']].fillna(x[['fare']].median())\n",
    "        y = data_df[label_name]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=test_size, random_state=split_seed, shuffle=True\n",
    "        )\n",
    "        if train:\n",
    "            self.raw_data = x_train, y_train\n",
    "        else:\n",
    "            self.raw_data = x_test, y_test\n",
    "\n",
    "        # Preprocess the data\n",
    "        x_train_processed, preprocessor = preprocess_train_data(\n",
    "            x_train, categorical_features=[\"sex\"]\n",
    "        )\n",
    "        x_train = pd.DataFrame(\n",
    "            x_train_processed, columns=preprocessor.get_feature_names_out()\n",
    "        )\n",
    "        x_test_processed = preprocess_test_data(x_test, preprocessor)\n",
    "        x_test = pd.DataFrame(\n",
    "            x_test_processed, columns=preprocessor.get_feature_names_out()\n",
    "        )\n",
    "\n",
    "        # Select data partition and convert to tensors\n",
    "        if train:\n",
    "            samples = x_train\n",
    "            labels = y_train\n",
    "        else:\n",
    "            samples = x_test\n",
    "            labels = y_test\n",
    "        self.samples = torch.tensor(samples.to_numpy(), dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.to_numpy(), dtype=torch.long)\n",
    "        self.features = preprocessor.get_feature_names_out()\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c7c1f-81f5-4806-ad20-358a79df93e6",
   "metadata": {},
   "source": [
    "Finally, we call the code above to load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ae2d1e0-ddab-419b-b741-6d4d6b531bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = TitanicDataset.create_datasets(\n",
    "    test_size=0.2,\n",
    "    split_seed=42,\n",
    ")\n",
    "train_dl = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4283a2e-986b-4554-89e3-3a0c4c152cbb",
   "metadata": {},
   "source": [
    "Note that the invertible transformer allows you to recover the original (unnormalised) feature values, as shown on the example below. You may find this helpful for understanding the produced explanations and commenting on them in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88f85249-8c4b-46b0-a856-76c972f524e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.125</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.7417</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pclass   age sibsp parch     fare   sex\n",
       "0    3.0  35.0   0.0   0.0    7.125  male\n",
       "1    3.0  20.0   1.0   1.0  15.7417  male\n",
       "2    3.0  28.0   0.0   0.0   7.8958  male\n",
       "3    3.0  28.0   0.0   0.0     8.05  male\n",
       "4    3.0  28.0   0.0   0.0     7.75  male"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.preprocessor.inverse_transform(test_dataset.samples[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441756a7-f828-4764-af69-4eb84b63a975",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93538903-f8cc-4f39-9593-f0ee82096b75",
   "metadata": {},
   "source": [
    "When faced with a new dataset, it is a good practice to perform an exploratory data analysis in order to understand the basic trends in the data. This will also allow you to put the explanations you obtain as part of this coursework into the relevant context. We will use the raw, unnormalised features for this purpose, as they are much more intuitive and human-understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a82a5efb-2ce7-4428-a03f-ee0f61f6dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_dataset.raw_data\n",
    "x_train['survived'] = y_train\n",
    "data_df = x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf759d8-e225-4482-a8ba-93d0a604d32e",
   "metadata": {},
   "source": [
    "We start by displaying the feature values and labels for a few samples. The dataset contains data regarding the survival of some of the passengers involved in the [Titanic maritime disaster](https://en.wikipedia.org/wiki/Sinking_of_the_Titanic). The features contained in the data are as follows:\n",
    "* `pclass`: Indicates the travelling class of the given passenger. Note that we treat this feature as numerical, as the different classes introduce a natural order.\n",
    "* `sex`: Indicates the sex of the passenger.\n",
    "* `age`: Provides the age of the passenger.\n",
    "* `sibsp`: Denotes the total number of siblings and spouses of the given passenger also travelling on RMS Titanic.\n",
    "* `parch`: Denotes the total number of parents or children of the given passenger also travelling on RMS Titanic.\n",
    "* `fare`: Indicates the fare paid by the passenger for the journey.\n",
    "* `survived`: The label indicating whether the patient survived the accident (1 = survived, 0 = did not survive).\n",
    "\n",
    "There are other features included in the original dataset (such aspassenger name or point of embarkation), but we choose to ignore them for the purposes of this coursework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9b42a-9f57-4502-8d00-9fda6bdb34cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.4000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass     sex   age  sibsp  parch      fare  survived\n",
       "772        3    male  17.0      0      0    7.8958         0\n",
       "543        2    male  36.0      0      0   10.5000         0\n",
       "289        1  female  18.0      0      2   79.6500         1\n",
       "10         1    male  47.0      1      0  227.5250         0\n",
       "147        1    male  28.0      0      0   42.4000         0\n",
       "...      ...     ...   ...    ...    ...       ...       ...\n",
       "1095       3  female  28.0      0      0    7.6292         0\n",
       "1130       3  female  18.0      0      0    7.7750         0\n",
       "1294       3    male  28.5      0      0   16.1000         0\n",
       "860        3  female  26.0      0      0    7.9250         1\n",
       "1126       3  female  28.0      0      0    7.8958         0\n",
       "\n",
       "[1047 rows x 7 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8e9c2-2266-40c2-9d91-3bd25e633eb2",
   "metadata": {},
   "source": [
    "Let us visualise the correlation between the individual columns of the data, computed using the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient). Note that we excluded the `sex` feature from this visualisation, as it is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "465f7fb2-3f81-4f9a-9ff9-09f45d3a50e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "corr = data_df.drop(columns=[\"sex\"]).corr()\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    xticklabels=corr.columns.values,\n",
    "    yticklabels=corr.columns.values,\n",
    "    annot=True,\n",
    "    fmt='.2g',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba12652-00ee-42f2-b37c-7aabbd7d6b17",
   "metadata": {},
   "source": [
    "Since the previous plot does not include the categorical `sex` column, we also separately visualise its distribution, including the associated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e255d4-c9d4-4588-aeb3-f563c202b595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "grouped = data_df.groupby(['sex', 'survived']).size().unstack()\n",
    "\n",
    "# Plotting\n",
    "ax = grouped.plot(kind='bar', stacked=True, color=['#a51900', '#02893b'], xlabel=\"Sex\", ylabel=\"Count\")\n",
    "plt.legend(['No', 'Yes'], title=\"Survived\")\n",
    "\n",
    "# Adding annotations\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.text(x + width/2, y + height/2, f'{int(height)}\\n({height/grouped.sum().sum()*100:.1f}%)', \n",
    "            horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2dc6b6-a871-4509-8049-52d84833c417",
   "metadata": {},
   "source": [
    "**Task 1(a)**: <br />\n",
    "**(i)** Considering the above visualisations, are there any trends or patterns that you can identify in the data? <br />\n",
    "**(ii)** Without having access to any particular model or the associated explanations, which features would you expect to be the most and least important for a neural network trained on the dataset? How can you tell and how certain can you be of your assessment? <br />\n",
    "**(iii)** Apart from inspecting the above plots, is there anything else you could do as part of the exploratory analysis that would allow you to better understand the data and the behaviour of the models trained on it? <br />\n",
    "Please write your answers in a few sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a7e4a2-988d-4580-9fb9-a93f76c3164b",
   "metadata": {},
   "source": [
    "## Model Initialisation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4435873c-e279-45c9-b2b0-38faedba32ac",
   "metadata": {},
   "source": [
    "First, we define a global device variable to enable running this code on a GPU or a CPU, as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65a56bef-3daa-44aa-8e57-d001b3bff2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a96541-7047-4c2b-845f-b823f4a8b239",
   "metadata": {},
   "source": [
    "Here, we define several utility functions for constructing, training and evaluating neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "395dd993-e2e1-46a8-b727-9f646ce4e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torcheval.metrics.functional import binary_f1_score, binary_accuracy, binary_auroc\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def construct_nn(nn_dims, activation_fun):\n",
    "    \"\"\"\n",
    "    Constructs a neural network with the specified architecture.\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    for i in range(1, len(nn_dims)):\n",
    "        in_dim, out_dim = nn_dims[i-1], nn_dims[i]\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        layers.append(activation_fun())\n",
    "    # Remove the last activation layer and add Sigmoid instead\n",
    "    layers = layers[:-1]\n",
    "    layers.append(nn.Sigmoid())\n",
    "    \n",
    "    return nn.Sequential(*layers).to(DEVICE)\n",
    "\n",
    "def train_nn(model, train_dl, num_epochs=100):\n",
    "    \"\"\"\n",
    "    Trains a neural network using the data from the provided data loader.\n",
    "    \"\"\"\n",
    "    loss_fun = nn.BCELoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in tqdm(range(num_epochs), leave=False):\n",
    "        total_loss = 0\n",
    "        for i, (x, y) in list(enumerate(train_dl)):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = loss_fun(out.squeeze(-1), y.float())\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        losses.append(total_loss)\n",
    "\n",
    "def eval_nn(model, test_dataset):\n",
    "    \"\"\"\n",
    "    Evaluates binary classification performance of a model on the given\n",
    "    test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    loss_fun = nn.BCELoss()\n",
    "    predictions = model(test_dataset.samples.to(DEVICE))\n",
    "    labels = test_dataset.labels.unsqueeze(-1).to(DEVICE)\n",
    "    loss = loss_fun(predictions, labels.float()).item()\n",
    "\n",
    "    predictions = predictions.squeeze(-1).detach()\n",
    "    labels = labels.squeeze(-1).detach()\n",
    "    f1 = binary_f1_score(predictions, labels).item()\n",
    "    accuracy = binary_accuracy(predictions, labels).item()\n",
    "    auc = binary_auroc(predictions, labels).item()\n",
    "\n",
    "    return loss, f1, accuracy, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3495eeb-14fa-4ae2-aaaf-b24c64ab8ef9",
   "metadata": {},
   "source": [
    "In this cell, we initialise and train the neural model that we will be explaining in this coursework. For a real-world application, you would typically wish to perform a full hyperparameter search in order to identify the most effective model architecture. However, achieving a maximum performance is not the objective of this coursework, so we just pre-define a model that performs reasonably well on the given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68254f96-7821-4a53-8615-2edbfee294ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————[ Model training ]———————\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e130ade5ed4a46b48c25dd6412b45b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "\n",
      "———————[ Evaluation ]———————\n",
      "F1 score: 0.75\n",
      "Accuracy: 0.80\n",
      "AUC: 0.83\n"
     ]
    }
   ],
   "source": [
    "def print_metric(name, value):\n",
    "    print(f\"{name}: {'{:.2f}'.format(round(value, 2))}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "model = construct_nn([7, 256, 256, 1], nn.ReLU).to(DEVICE)\n",
    "\n",
    "print(\"———————[ Model training ]———————\")\n",
    "train_nn(model, train_dl, num_epochs=1000)\n",
    "print(\"Training completed!\")\n",
    "print()\n",
    "\n",
    "print(\"———————[ Evaluation ]———————\")\n",
    "test_loss, f1, accuracy, auc = eval_nn(model, test_dataset)\n",
    "print_metric(\"F1 score\", f1)\n",
    "print_metric(\"Accuracy\", accuracy)\n",
    "print_metric(\"AUC\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6034c1b-500d-4e02-a6e7-742d62208c8e",
   "metadata": {},
   "source": [
    "## Feature Attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa2e83-1342-4a8c-b1e7-d1188455eeb6",
   "metadata": {},
   "source": [
    "In this section of the coursework, you will implement SHAP as introduced in the lectures and conduct additional experiments with various feature attribution methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e7328-82bd-41aa-bcb9-6488e575c3f4",
   "metadata": {},
   "source": [
    "### SHAP Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf73aa-f5e3-4c36-9875-19e38c5d5c99",
   "metadata": {},
   "source": [
    "**Task 2(a)(i)**: As a first step in implementing SHAP, define a `compute_coefficient` function to compute the SHAP coalition coefficient/weight as specified by the formula from the lectures:\n",
    "\n",
    "$$g_{SHAP}(\\mathcal{M},\\mathbf{x},i) = \\sum_{\\mathbf{z} \\subseteq \\mathbf{x}}{\\frac{|\\mathbf{z}|!(n - |\\mathbf{z}| - 1)! }{n!} \\mathcal{M}( \\mathbf{z}) - \\mathcal{M}(\\mathbf{z}_{-i})} \\nonumber$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "564deb60-0275-4b75-a2a8-b2e61ef4563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_coefficient(num_in_coalition, total_features):\n",
    "    \"\"\"\n",
    "    Computes the SHAP coefficient for a coalition.\n",
    "\n",
    "    Parameters:\n",
    "        num_in_coalition (int): The number of features in the given coalition\n",
    "        total_features (int): The total number of considered features\n",
    "\n",
    "    Returns:\n",
    "        coefficient (float): The SHAP weight for the given coalition\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "\n",
    "    if total_features == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "\n",
    "    numerator = math.factorial(num_in_coalition) * math.factorial(total_features - num_in_coalition - 1)\n",
    "    denominator = math.factorial(total_features)\n",
    "    \n",
    "    return numerator / denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8131b77-5eac-471c-a1a8-ff138f4b4541",
   "metadata": {},
   "source": [
    "**Task 2(a)(ii)**: Next, define a function `generate_coalitions`, which will return the list representing all the possible coalitions for a possible feature.\n",
    "\n",
    "Hint #1: You may find it helpful to use [itertools](https://docs.python.org/3/library/itertools.html) and [Python generators](https://wiki.python.org/moin/Generators) for implementing this function.\n",
    "\n",
    "Hint #2: Passing a full list of feature IDs is not strictly necessary here, but you will find this list helpful for implementing other functions, so we also recommend taking it as a parameter here. As an example, for the Titanic dataset, this list could look like `[0, 1, 2, 3, 4, 5, 5]` (note the repeated `5` for the one-hot-encoded `sex` feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e60209-d01b-4947-bba5-e13b5385d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_coalitions(feature_ids, target_feature_id):\n",
    "    \"\"\"\n",
    "    Generates the possible feature coalitions for the purpose of computing the Shapley value\n",
    "    for the target feature.\n",
    "\n",
    "    Parameters:\n",
    "        feature_ids (list): A list with feature IDs from 0 to N (where N is\n",
    "            the total number of features) identifying the used features. Distinct\n",
    "            columns for one-hot-encoded features should be assigned the same\n",
    "            numerical ID.\n",
    "        target_feature_id (int): The ID of the removed feature for which the coalitions\n",
    "            should be generated.\n",
    "\n",
    "    Retruns:\n",
    "        coalitions (list): A nested list structure of coalitions in the form:\n",
    "            [(set(coalition 1 in features set), set(coalition 1 out features set)), ...].\n",
    "            Note that feature_id should not appear in either of the in/out lists.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Your code here\n",
    "    coalitions = []\n",
    "    \n",
    "    # Exclude the target feature ID from the list of feature_ids\n",
    "    remaining_features = [feature for feature in feature_ids if feature != target_feature_id]\n",
    "    \n",
    "    # Generate all subsets of remaining features\n",
    "    for subset_size in range(1, len(remaining_features) + 1):\n",
    "        # Iterate through all combinations of the remaining features\n",
    "        for coalition_in_features in itertools.combinations(remaining_features, subset_size):\n",
    "            # Coalition of features included in the subset\n",
    "            coalition_in_features_set = set(coalition_in_features)\n",
    "            # Coalition of features excluded from the subset\n",
    "            coalition_out_features_set = set(feature_ids) - coalition_in_features_set - {target_feature_id}\n",
    "            coalitions.append((coalition_in_features_set, coalition_out_features_set))\n",
    "    \n",
    "    return coalitions    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e649eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({1}, {2, 3, 4, 5}), ({2}, {1, 3, 4, 5}), ({3}, {1, 2, 4, 5}), ({4}, {1, 2, 3, 5}), ({5}, {1, 2, 3, 4}), ({5}, {1, 2, 3, 4}), ({1, 2}, {3, 4, 5}), ({1, 3}, {2, 4, 5}), ({1, 4}, {2, 3, 5}), ({1, 5}, {2, 3, 4}), ({1, 5}, {2, 3, 4}), ({2, 3}, {1, 4, 5}), ({2, 4}, {1, 3, 5}), ({2, 5}, {1, 3, 4}), ({2, 5}, {1, 3, 4}), ({3, 4}, {1, 2, 5}), ({3, 5}, {1, 2, 4}), ({3, 5}, {1, 2, 4}), ({4, 5}, {1, 2, 3}), ({4, 5}, {1, 2, 3}), ({5}, {1, 2, 3, 4}), ({1, 2, 3}, {4, 5}), ({1, 2, 4}, {3, 5}), ({1, 2, 5}, {3, 4}), ({1, 2, 5}, {3, 4}), ({1, 3, 4}, {2, 5}), ({1, 3, 5}, {2, 4}), ({1, 3, 5}, {2, 4}), ({1, 4, 5}, {2, 3}), ({1, 4, 5}, {2, 3}), ({1, 5}, {2, 3, 4}), ({2, 3, 4}, {1, 5}), ({2, 3, 5}, {1, 4}), ({2, 3, 5}, {1, 4}), ({2, 4, 5}, {1, 3}), ({2, 4, 5}, {1, 3}), ({2, 5}, {1, 3, 4}), ({3, 4, 5}, {1, 2}), ({3, 4, 5}, {1, 2}), ({3, 5}, {1, 2, 4}), ({4, 5}, {1, 2, 3}), ({1, 2, 3, 4}, {5}), ({1, 2, 3, 5}, {4}), ({1, 2, 3, 5}, {4}), ({1, 2, 4, 5}, {3}), ({1, 2, 4, 5}, {3}), ({1, 2, 5}, {3, 4}), ({1, 3, 4, 5}, {2}), ({1, 3, 4, 5}, {2}), ({1, 3, 5}, {2, 4}), ({1, 4, 5}, {2, 3}), ({2, 3, 4, 5}, {1}), ({2, 3, 4, 5}, {1}), ({2, 3, 5}, {1, 4}), ({2, 4, 5}, {1, 3}), ({3, 4, 5}, {1, 2}), ({1, 2, 3, 4, 5}, set()), ({1, 2, 3, 4, 5}, set()), ({1, 2, 3, 5}, {4}), ({1, 2, 4, 5}, {3}), ({1, 3, 4, 5}, {2}), ({2, 3, 4, 5}, {1}), ({1, 2, 3, 4, 5}, set())]\n"
     ]
    }
   ],
   "source": [
    "# test the implementation of generate_coalitions\n",
    "\n",
    "feature_ids = [0, 1, 2, 3, 4, 5, 5]\n",
    "target_feature_id = 0\n",
    "\n",
    "coalitions = generate_coalitions(feature_ids, target_feature_id)\n",
    "\n",
    "print(coalitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6fe694-5010-47c6-a3dc-68ffd032eb1b",
   "metadata": {},
   "source": [
    "**Task 2(a)(iii)**: Next, implement a function `delete_features` that deletes the specified features from the given input tensor `x`. In contrast with the setting in the SHAP tutorial, the majority of features considered in this coursework are non-binary, which makes the deletion of features slightly more challenging. The general procedure for performing the deletion can be described as follows:\n",
    "1. For each sample in `x` and each deleted feature, randomly sample the value of the deleted feature from another data point in the background dataset\n",
    "2. If the sampled value is identical to the current value of the deleted feature, continue sampling new values until finding one that differs. This ensures that feature deletion actually changes the values of categorical variables or variables with few possible values.\n",
    "3. Replace the value of the deleted feature in the currently considered sample with the newly sampled value\n",
    "\n",
    "Hint #1: Boolean tensor masks \"selecting\" certain features can be very helpful here.\n",
    "\n",
    "Hint #2: Make sure not to overwrite values in the original `x` when deleting features. Instead, the function should return a new tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a75928ee-3f2b-4427-8f41-45cfbe239eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_features(x, background_dataset, feature_ids, deleted_feature_ids):\n",
    "    \"\"\"\n",
    "    Deletes the specified features from inputs x using the background dataset.\n",
    "\n",
    "    Parameters:\n",
    "        x (Tensor): A tensor of inputs with the shape (batch_size, num_features).\n",
    "        background_dataset (Tensor): A tensor of background data samples with the same shape as x.\n",
    "        feature_ids (list): A list with feature IDs, same as in generate_coalitions.\n",
    "        deleted_feature_ids (set): A set with feature IDs to be deleted from x.\n",
    "\n",
    "    Returns:\n",
    "        x_deleted (tensor): A new tensor of inputs with the specified features deleted.\n",
    "    \"\"\"    \n",
    "    # Make the sampling deterministic\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # TODO: Your code here\n",
    "\n",
    "    # take a copy so the input x is not overwritten\n",
    "    x_deleted = x.clone()\n",
    "\n",
    "\n",
    "    # create a boolean mask for the deleted features\n",
    "    deleted_feature_indices = [i for i, f_id in enumerate(feature_ids) if f_id in deleted_feature_ids]\n",
    "    mask = torch.zeros(x.size(1), dtype=torch.bool)  \n",
    "    \n",
    "    mask[deleted_feature_indices] = True  # set True for deleted features\n",
    "    \n",
    "    # iterate over each sample in x\n",
    "    for i in range(x.size(0)):\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # randomly select from the background dataset\n",
    "            sample_index = np.random.randint(0, background_dataset.size(0))\n",
    "            \n",
    "            sampled_values = background_dataset[sample_index, mask]\n",
    "            \n",
    "            # ensure the sampled values are different from the current values\n",
    "            if not torch.any(sampled_values == x_deleted[i, mask]):\n",
    "                break\n",
    "\n",
    "        # replace the values of the deleted features with the sampled values\n",
    "        x_deleted[i, ~mask] = x[i, ~mask]\n",
    "        x_deleted[i, mask] = sampled_values\n",
    "\n",
    "    return x_deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f198a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  True,  True, False, False],\n",
       "        [ True, False,  True,  True,  True, False, False],\n",
       "        [ True, False,  True,  True,  True, False, False],\n",
       "        [ True, False,  True,  True,  True, False, False],\n",
       "        [ True, False,  True,  True,  True, False, False]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the implementation of delete_features\n",
    "\n",
    "random_indices = np.random.choice(len(test_dataset), 5, replace = False)\n",
    "selected_rows = test_dataset.samples[random_indices]\n",
    "\n",
    "selected_rows\n",
    "x_deleted = delete_features(selected_rows,  test_dataset.samples, [0,1,2,3,4,5,5], [1,5])\n",
    "x_deleted == selected_rows # This returns `False` if features were successfully deleted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679f0dc8-1542-4989-b148-41d5e5889e5b",
   "metadata": {},
   "source": [
    "**Task 2(a)(iv)**: Finally, put everything together in the `shap_attribute` function, which will compute the SHAP attributions for the given input and model. Note that the function also takes in a `target_idx` specifying for which output neuron the explanations should be computed. This is not strictly necessary for the Titanic model, which only has a single Sigmoid output, but will be needed once you start working with a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6861b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_attribute(model, x, background_dataset, feature_ids, target_idx=0):\n",
    "    \"\"\"\n",
    "    Computes the SHAP attributions for the given input and model.\n",
    "\n",
    "    Parameters:\n",
    "        model (Object): A PyTorch model for which the attributions should be computed.\n",
    "        x (Tensor): Inputs for which the explanations should be computed, in shape (batch_size, num_features).\n",
    "        background_dataset (Tensor): A tensor of background data samples with the same shape as x.\n",
    "        feature_ids (list): A list with feature IDs, same as in generate_coalitions.\n",
    "        target_idx (int): The ID of the target neuron for which to compute an explanation.\n",
    "\n",
    "    Returns:\n",
    "        attributions (Tensor): A tensor of SHAP attributions, with the same shape as the input.\n",
    "    \"\"\"\n",
    "    # Initialize the attributions tensor\n",
    "    batch_size, num_features = x.shape\n",
    "    attributions = torch.zeros_like(x)\n",
    "\n",
    "    # Iterate over each feature to compute its SHAP value\n",
    "    for i, target_feature_id in enumerate(feature_ids):  # Use set to handle duplicates\n",
    "        # Generate all coalitions for the target feature\n",
    "        coalitions = generate_coalitions(feature_ids, target_feature_id)\n",
    "\n",
    "        shap_value=0\n",
    "        # Iterate over each coalition\n",
    "        for coalition_in, coalition_out in coalitions:\n",
    "            # Compute the SHAP coefficient for this coalition\n",
    "            num_in_coalition = len(coalition_in)\n",
    "            total_features = len(feature_ids)  # Use set to handle duplicates\n",
    "            coefficient = compute_coefficient(num_in_coalition, total_features)\n",
    "\n",
    "            # Delete features in the coalition_out set\n",
    "            x_deleted = delete_features(x, background_dataset, feature_ids, coalition_out)\n",
    "\n",
    "            # Compute the model's output with the coalition_in features\n",
    "            with torch.no_grad():\n",
    "                output_in = model(x_deleted)[:, target_idx]\n",
    "\n",
    "            # Delete features in the coalition_in set (including the target feature)\n",
    "            x_deleted_target = delete_features(x, background_dataset, feature_ids, coalition_in | {target_feature_id})\n",
    "\n",
    "            # Compute the model's output without the coalition_in features\n",
    "            with torch.no_grad():\n",
    "                output_out = model(x_deleted_target)[:, target_idx]\n",
    "\n",
    "            # Compute the marginal contribution of the target feature\n",
    "            marginal_contribution = output_in - output_out\n",
    "            shap_value+=coefficient*marginal_contribution\n",
    "            \n",
    "        attributions[:, i] = shap_value\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017834b-bf1c-48e4-ab1c-ff0d26ccab5c",
   "metadata": {},
   "source": [
    "### Additional Explanation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33325644-8c95-4e9f-aa94-9cf9206d2268",
   "metadata": {},
   "source": [
    "Apart from SHAP, which you just implemented, you will also be experimenting with two more feature attribution methods implemented in the [Captum](https://captum.ai/) library — [Shapley Value Sampling](https://captum.ai/api/shapley_value_sampling.html) and [DeepLIFT](https://captum.ai/api/deep_lift.html). Shapley Value Sampling is a more computationally tractable approximation of SHAP and computes the scores by randomly sampling a fixed number of coalitions instead of considering all of them. Meanwhile, DeepLIFT is a fast gradient-based attribution method specifically designed for neural models. If you are interested, you can learn more about DeepLIFT in [its original paper](https://arxiv.org/abs/1704.02685).\n",
    "\n",
    "To get you started, we provide an example of how to use the Captum library to generate Shapley Value Sampling attributions for the first sample from the Titanic test set (note that the library also allows you to compute attributions for a batch of inputs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "974eca85-1658-4222-95fc-bf3d180baeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.1988,  0.0000,  0.0000,  0.1638, -0.5639, -0.5639]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from captum.attr import ShapleyValueSampling\n",
    "\n",
    "# Note that this is similar to feature_ids from the implementation above,\n",
    "# but the shape and the data type are different\n",
    "feature_mask = torch.tensor([[0, 1, 2, 3, 4, 5, 5]]).to(DEVICE)\n",
    "svs = ShapleyValueSampling(model)\n",
    "attributions = svs.attribute(test_dataset.samples[[0]].to(DEVICE), target=0, feature_mask=feature_mask)\n",
    "attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e108b2-15d8-4c0b-bf6f-a64a4fe3b9e2",
   "metadata": {},
   "source": [
    "Notice that, in contrast with the SHAP implementation above, we did not need to pass in the background dataset. This is because Captum takes a slightly different approach to deleting features and instead replaces them with a pre-specified baseline value (see the `baselines` parameter description in the [documentation](https://captum.ai/api/shapley_value_sampling.html)). For the purposes of this coursework, it is fine to use the default (zero) baseline for both Shapley Value Sampling and DeepLIFT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c24e08-7871-44fe-afdd-d15c3c8d1fee",
   "metadata": {},
   "source": [
    "### Feature Attribution Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d4669-00e6-43bb-826f-c0f12aa45f96",
   "metadata": {},
   "source": [
    "In this section, you will conduct several experiments associated with feature attribution methods.\n",
    "\n",
    "**Task 2(b)**: Using your implementation of SHAP and Captum implementations of Shapley Value Sampling and DeepLIFT, compute feature attributions for 10 randomly selected instances from the Titanic test set. Then answer the following questions: <br />\n",
    "**(i)** Which features generally seem to be the most important and least important for the explained model according to each of the explanations? <br />\n",
    "**(ii)** Are there any substantial differences between the different attribution methods? What might be the possible reasons for the different methods returning different attribution scores? <br />\n",
    "**(iii)** Do the attribution scores match your expectations for the most/least important features from task 1(a)(ii)? What might be the reasons for a user's expected explanations differing from the computed attribution explanations? <br />\n",
    "**(iv)** Considering the insights gained from the exploratory data analysis and the feature attribution explanations, as well as the definitions of the explanations themselves, what are the potential advantages/disadvantages of each of these methods when trying to understand the behaviour of a model on a particular dataset? <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2680c1c-9276-45c1-94ae-c10a660b74f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([-1.0000,  0.2581,  0.0000,  0.5000,  7.0881,  0.0000,  1.0000]), tensor([ 0.0000, -0.4516,  1.0000,  0.0000, -0.0464,  1.0000,  0.0000]), tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -0.0940,  0.0000,  1.0000]), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5979, 0.0000, 1.0000]), tensor([-1.0000,  0.3548,  1.0000,  0.5000,  0.9276,  1.0000,  0.0000]), tensor([-0.5000, -0.3226,  0.0000,  0.0000, -0.0427,  0.0000,  1.0000]), tensor([-1.0000,  0.7742,  0.0000,  0.0000,  0.2278,  0.0000,  1.0000]), tensor([ 0.0000, -0.3871,  0.0000,  0.0000, -0.0752,  0.0000,  1.0000]), tensor([-0.5000, -0.8065,  1.0000,  1.0000,  0.3856,  1.0000,  0.0000]), tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -0.1035,  0.0000,  1.0000])]\n",
      "input_tensor tensor([[-1.0000,  0.2581,  0.0000,  0.5000,  7.0881,  0.0000,  1.0000],\n",
      "        [ 0.0000, -0.4516,  1.0000,  0.0000, -0.0464,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0940,  0.0000,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.5979,  0.0000,  1.0000],\n",
      "        [-1.0000,  0.3548,  1.0000,  0.5000,  0.9276,  1.0000,  0.0000],\n",
      "        [-0.5000, -0.3226,  0.0000,  0.0000, -0.0427,  0.0000,  1.0000],\n",
      "        [-1.0000,  0.7742,  0.0000,  0.0000,  0.2278,  0.0000,  1.0000],\n",
      "        [ 0.0000, -0.3871,  0.0000,  0.0000, -0.0752,  0.0000,  1.0000],\n",
      "        [-0.5000, -0.8065,  1.0000,  1.0000,  0.3856,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.1035,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Your code and experiments here\n",
    "import torch\n",
    "from captum.attr import ShapleyValueSampling, DeepLift\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Randomly select 10 instances from the Titanic test set\n",
    "random_indices = random.sample(range(len(test_dataset.samples)), 10)\n",
    "selected_samples = [test_dataset.samples[idx] for idx in random_indices]\n",
    "\n",
    "print(selected_samples)\n",
    "# Convert the selected samples to tensor and move them to the same device as the model\n",
    "input_tensor = torch.stack(selected_samples)\n",
    "print(\"input_tensor\", input_tensor)\n",
    "\n",
    "# Analyze results\n",
    "def analyze_attributions(attributions, feature_names):\n",
    "    avg_attributions = torch.mean(torch.abs(attributions), dim=0) # torch.abs(attributions)\n",
    "    ranked_features = sorted(zip(feature_names, avg_attributions), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Ranked Features:\")\n",
    "    for feature, score in ranked_features:\n",
    "        print(f\"{feature}: {score:.4f}\")\n",
    "    return ranked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93b151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1037, 7])\n",
      "tensor([[ 0.0889, -0.0807, -0.1040, -0.0344,  0.2962, -0.0973, -0.0973],\n",
      "        [ 0.0720,  0.3856,  0.1973,  0.1664,  0.1779,  0.2275,  0.2275],\n",
      "        [-0.2526, -0.1897, -0.0750, -0.2945, -0.3079, -0.1499, -0.1499],\n",
      "        [-0.2670, -0.0073, -0.1186, -0.0041, -0.1063, -0.1621, -0.1621],\n",
      "        [ 0.4144,  0.2094,  0.1698,  0.1449,  0.2294,  0.2550,  0.2550],\n",
      "        [-0.1043, -0.1918,  0.0211, -0.1389, -0.1788, -0.1536, -0.1536],\n",
      "        [ 0.0990, -0.1773,  0.0432, -0.1496, -0.0296, -0.1461, -0.1461],\n",
      "        [-0.3305, -0.0990, -0.1506, -0.1860, -0.2190, -0.2161, -0.2161],\n",
      "        [ 0.2240,  0.2132,  0.1295,  0.1019,  0.1197,  0.1264,  0.1264],\n",
      "        [-0.2409, -0.1485, -0.1490, -0.1823, -0.2135, -0.1798, -0.1798]])\n",
      "tensor([-0.0297, -0.0086, -0.0036, -0.0577, -0.0232, -0.0496, -0.0496])\n",
      "Ranked Features:\n",
      "pclass: 0.2094\n",
      "fare: 0.1878\n",
      "sex_m: 0.1714\n",
      "sex_f: 0.1714\n",
      "age: 0.1702\n",
      "parch: 0.1403\n",
      "sibsp: 0.1158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pclass', tensor(0.2094)),\n",
       " ('fare', tensor(0.1878)),\n",
       " ('sex_m', tensor(0.1714)),\n",
       " ('sex_f', tensor(0.1714)),\n",
       " ('age', tensor(0.1702)),\n",
       " ('parch', tensor(0.1403)),\n",
       " ('sibsp', tensor(0.1158))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- SHAP Implementation -------------------------\n",
    "\n",
    "# Create the background dataset for SHAP, which should have the same shape as the input tensor.\n",
    "# This dataset is typically a subset of the training data used to approximate the expected model output.\n",
    "\n",
    "# Construct the background dataset by excluding the randomly selected test samples from the training dataset.\n",
    "background_samples = [train_dataset.samples[idx] for idx in range(len(train_dataset.samples)) if idx not in random_indices]\n",
    "\n",
    "# Convert the list of background samples into a PyTorch tensor\n",
    "background_dataset = torch.stack(background_samples)\n",
    "\n",
    "# Print the size of the background dataset for verification\n",
    "print(background_dataset.size())\n",
    "\n",
    "# Define the feature indices to be used for SHAP attribution analysis.\n",
    "feature_ids = [0, 1, 2, 3, 4, 5, 5]\n",
    "\n",
    "# Compute SHAP attributions for the given model, input tensor, and background dataset.\n",
    "attributions_shap = shap_attribute(model, input_tensor, background_dataset, feature_ids)\n",
    "\n",
    "# Print the raw SHAP attributions to inspect the results\n",
    "print(attributions_shap)\n",
    "\n",
    "# Compute and print the mean SHAP attribution across all instances to understand feature importance\n",
    "print(attributions_shap.mean(dim=0))\n",
    "\n",
    "# Define human-readable feature names corresponding to the feature indices\n",
    "feature_names = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"sex_m\", \"sex_f\"]\n",
    "\n",
    "# Analyze and visualize the SHAP attributions for better interpretability\n",
    "analyze_attributions(attributions_shap, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d13d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0251,  0.1321,  0.0000,  0.1669,  0.7283, -0.2619, -0.2619],\n",
      "        [ 0.0000,  0.3414,  0.4085,  0.0000,  0.2466, -0.2102, -0.2102],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2567, -0.3737, -0.3737],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.5078,  0.0834,  0.0834],\n",
      "        [ 0.5806,  0.0310,  0.1433, -0.0906,  0.1477, -0.0215, -0.0215],\n",
      "        [ 0.3112, -0.0902,  0.0000,  0.0000,  0.0337, -0.4619, -0.4619],\n",
      "        [ 0.4926,  0.3191,  0.0000,  0.0000,  0.3193, -0.3854, -0.3854],\n",
      "        [ 0.0000, -0.0675,  0.0000,  0.0000,  0.2931, -0.2580, -0.2580],\n",
      "        [ 0.4379,  0.2193,  0.1215,  0.0077,  0.0012,  0.0030,  0.0030],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2583, -0.4033, -0.4033]])\n",
      "mean tensor([ 0.1847,  0.0885,  0.0673,  0.0084,  0.2793, -0.2289, -0.2289])\n",
      "Ranked Features:\n",
      "fare: 0.2793\n",
      "sex_m: 0.2462\n",
      "sex_f: 0.2462\n",
      "pclass: 0.1847\n",
      "age: 0.1201\n",
      "sibsp: 0.0673\n",
      "parch: 0.0265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('fare', tensor(0.2793)),\n",
       " ('sex_m', tensor(0.2462)),\n",
       " ('sex_f', tensor(0.2462)),\n",
       " ('pclass', tensor(0.1847)),\n",
       " ('age', tensor(0.1201)),\n",
       " ('sibsp', tensor(0.0673)),\n",
       " ('parch', tensor(0.0265))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Your code and experiments here\n",
    "\n",
    "# ------------------ Shapley Value Sampling using Captum -------------------\n",
    "\n",
    "svs = ShapleyValueSampling(model)\n",
    "\n",
    "# Create a feature mask (same as feature_ids)\n",
    "feature_mask = torch.tensor([[0, 1, 2, 3, 4, 5, 5]]) \n",
    "\n",
    "# Define the baseline data (reference input) as a tensor of zeros with the same shape as the input tensor.\n",
    "baseline_data = torch.zeros_like(input_tensor)\n",
    "\n",
    "\n",
    "# Compute Shapley Value Sampling attributions for the input tensor.\n",
    "svs_attribution = svs.attribute(input_tensor, target=0, feature_mask=feature_mask, baselines=baseline_data)\n",
    "\n",
    "# Print the computed attributions to inspect individual feature contributions\n",
    "print(svs_attribution)\n",
    "\n",
    "# Compute and print the mean attributions across all samples to understand overall feature importance\n",
    "print(\"Mean attribution:\", svs_attribution.mean(dim=0))\n",
    "\n",
    "# Analyze and visualize the attributions using the feature names\n",
    "analyze_attributions(svs_attribution, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be00fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2030,  0.0697,  0.0747,  0.0224,  0.3090, -0.0155, -0.2640],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "Ranked Features:\n",
      "fare: 0.3790\n",
      "sex_f: 0.2640\n",
      "pclass: 0.2388\n",
      "age: 0.1196\n",
      "sibsp: 0.0747\n",
      "sex_m: 0.0548\n",
      "parch: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUNITA\\anaconda3\\lib\\site-packages\\captum\\_utils\\gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUNITA\\anaconda3\\lib\\site-packages\\captum\\attr\\_core\\deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('fare', tensor(0.3790, grad_fn=<UnbindBackward0>)),\n",
       " ('sex_f', tensor(0.2640, grad_fn=<UnbindBackward0>)),\n",
       " ('pclass', tensor(0.2388, grad_fn=<UnbindBackward0>)),\n",
       " ('age', tensor(0.1196, grad_fn=<UnbindBackward0>)),\n",
       " ('sibsp', tensor(0.0747, grad_fn=<UnbindBackward0>)),\n",
       " ('sex_m', tensor(0.0548, grad_fn=<UnbindBackward0>)),\n",
       " ('parch', tensor(0.0404, grad_fn=<UnbindBackward0>))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------ DeepLIFT Attribution using Captum -------------------\n",
    "\n",
    "# Initialize the DeepLIFT attribution method from Captum\n",
    "# DeepLIFT helps identify how much each input feature contributes to the model’s prediction\n",
    "deep_lift = DeepLift(model)\n",
    "\n",
    "# Define the baseline data (reference input) as a tensor of zeros with the same shape as the input tensor.\n",
    "baseline_data = torch.zeros_like(input_tensor)\n",
    "\n",
    "# Compute DeepLIFT attributions for the input tensor.\n",
    "deeplift_attribution = deep_lift.attribute(input_tensor, target=0, baselines=baseline_data)\n",
    "\n",
    "# Print the mean attributions across all samples to understand overall feature importance\n",
    "print(deeplift_attribution.mean(dim=0))\n",
    "\n",
    "# Analyze and visualize the DeepLIFT attributions using the feature names\n",
    "analyze_attributions(deeplift_attribution, feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f1001-218e-46a8-b4cf-303f2939c234",
   "metadata": {},
   "source": [
    "**Task 2(c)**: Perform a quantitative evaluation of the different attribution methods by computing their mean [infidelity](https://captum.ai/api/metrics.html) on the full Titanic dataset. On a high level, infidelity aims to estimate how closely the generated explanations correspond with the behaviour of the explained model by slightly perturbing the inputs and measuring how much the observed change in the model output differs from the change predicted by the corresponding feature attributions (when considering a linear model with the same weights as the feature attribution scores). If you are interested, you can find more details regarding this metric in [the original paper](https://arxiv.org/abs/1901.09392). A downside of the infidelity metric is that one needs to define a suitable perturbation function for changing the model inputs, which can significantly affect the results. In this coursework, we provide you with a perturbation function adding Gaussian noise to continuous features and performing resampling for categorical features. In your evaluation, you should experiment with two or three different standard deviations and categorical resampling probabilities. Once you are done, add a table summarising the results to your report and comment on the findings. Note that lower infidelity scores are better.\n",
    "\n",
    "Note: You should use `normalize=True` and `n_perturb_samples=10` as parameters to the Captum's infidelity function and set the same Torch and NumPy seeds before computing the infidelity for each method (so that all methods are evaluated using the same sample perturbations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ffeb0f4-180f-4c7c-8a3f-258d3725ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.metrics import infidelity, infidelity_perturb_func_decorator\n",
    "\n",
    "def perturb_func_constructor(noise_scale, cat_resample_proba, background_dataset, feature_ids, n_perturb_samples=10):\n",
    "    \"\"\"\n",
    "    You can call this function to construct a perturbation function with the desired parameters,\n",
    "    which can then be provided as the perturb_func parameter to the infidelity metric implementation\n",
    "    from Captum.\n",
    "\n",
    "     Parameters:\n",
    "        noise_scale (float): A standard deviation of the Gaussian noise added to the continuous features.\n",
    "        cat_resample_proba (float): Probability of resampling a categorical feature.\n",
    "        background_dataset (Tensor): A tensor of background data samples with the shape (num_samples, num_features).\n",
    "        feature_ids (list): A list with feature IDs, same as in generate_coalitions.\n",
    "        n_perturb_samples (int): The number of perturbed samples for each input. Should match the value\n",
    "            of the corresponding parameter to the Captum's infidelity function.\n",
    "\n",
    "    Returns:\n",
    "        perturb_func (function): A perturbation function compatible with Captum\n",
    "    \"\"\"\n",
    "    @infidelity_perturb_func_decorator(True)\n",
    "    def perturb_func(inputs):        \n",
    "        # Construct masks for noise and resampling categorical variables\n",
    "        noise_mask = torch.ones(1, inputs.size(1)).to(DEVICE)\n",
    "        # We assume that categorical features are one-hot-encoded\n",
    "        i = 0\n",
    "        current_span_start = 0\n",
    "        categorical_spans = []\n",
    "        while i < len(feature_ids) - 1:    \n",
    "            if feature_ids[i] != feature_ids[i + 1] and current_span_start != i:\n",
    "                categorical_spans.append((current_span_start, i))\n",
    "                current_span_start = i + 1\n",
    "            elif feature_ids[i] != feature_ids[i + 1]:\n",
    "                current_span_start = i + 1\n",
    "            elif feature_ids[i] == feature_ids[i + 1] and i == len(feature_ids) - 2:\n",
    "                categorical_spans.append((current_span_start, i + 1))\n",
    "            i += 1\n",
    "                \n",
    "        cat_resample_masks = []\n",
    "        for i, (s, e) in enumerate(categorical_spans):\n",
    "            cat_resample_mask = torch.zeros(inputs.shape).to(DEVICE)\n",
    "            probabilities = torch.full((inputs.size(0), 1), cat_resample_proba)\n",
    "            resample_tensor = torch.bernoulli(probabilities)\n",
    "            noise_mask[:, s:e] = 0.\n",
    "            cat_resample_mask[:, s:e] = resample_tensor\n",
    "            cat_resample_masks.append(cat_resample_mask)\n",
    "\n",
    "        # Add noise to continuous features only\n",
    "        noise = torch.tensor(np.random.normal(0, noise_scale, inputs.shape)).float().to(DEVICE) * noise_mask\n",
    "        perturbed_inputs = inputs - noise\n",
    "\n",
    "        # Randomly resample categorical variables\n",
    "        if categorical_spans:\n",
    "            expanded_background_dataset = background_dataset.repeat((n_perturb_samples, 1))\n",
    "            for cat_resample_mask in cat_resample_masks:\n",
    "                random_perm = torch.randperm(expanded_background_dataset.size(0))\n",
    "                random_samples = expanded_background_dataset[random_perm[:inputs.size(0)]]\n",
    "                perturbed_inputs = perturbed_inputs * (1 - cat_resample_mask) + random_samples * cat_resample_mask\n",
    "\n",
    "        return perturbed_inputs\n",
    "\n",
    "    return perturb_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27347c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047\n",
      "262\n",
      "torch.Size([1309, 7])\n",
      "tensor([[ 0.0000, -0.3548,  0.0000,  ..., -0.0940,  0.0000,  1.0000],\n",
      "        [-0.5000,  0.2581,  0.0000,  ..., -0.0570,  0.0000,  1.0000],\n",
      "        [-1.0000, -0.3226,  0.0000,  ...,  0.9276,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.2258,  0.0000,  ..., -0.0975,  1.0000,  0.0000],\n",
      "        [-1.0000,  0.7097,  1.0000,  ...,  2.8049,  0.0000,  1.0000],\n",
      "        [-1.0000, -0.1290,  0.0000,  ...,  0.4984,  1.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Print the number of samples in the training dataset\n",
    "print(\"Number of training samples:\", len(train_dataset.samples))\n",
    "\n",
    "# Print the number of samples in the test dataset\n",
    "print(\"Number of test samples:\", len(test_dataset.samples))\n",
    "\n",
    "# Concatenate the training and test datasets to create a single unified dataset\n",
    "whole_dataset = torch.cat([train_dataset.samples, test_dataset.samples], dim=0)\n",
    "\n",
    "# Verify the shape of the concatenated dataset\n",
    "print(\"Shape of the combined dataset:\", whole_dataset.shape)\n",
    "\n",
    "# Print the full dataset (use cautiously if the dataset is large)\n",
    "print(\"Combined dataset:\\n\", whole_dataset)\n",
    "\n",
    "# Define the feature indices to be used for analysis or attributions\n",
    "feature_ids = [0, 1, 2, 3, 4, 5, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34113db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shap_attribute function to compute SHAP values for feature importance analysis\n",
    "attributions_shap = shap_attribute(model, whole_dataset, whole_dataset, feature_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d65e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline data for SHAP or DeepLIFT attribution, initialized as zeros \n",
    "baseline_data = torch.zeros_like(whole_dataset)\n",
    "\n",
    "# Calculate SHAP values using the SVS method (SHAP Values with SHAP-Vanishing Strategy)\n",
    "svs_attribution = svs.attribute(whole_dataset, target=0, feature_mask=feature_mask, baselines=baseline_data)\n",
    "\n",
    "# Calculate SHAP values using the DeepLIFT method\n",
    "deeplift_attribution = deep_lift.attribute(whole_dataset, target=0, baselines=baseline_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a36cb06b-f3ae-4888-905f-54d8cb5ae7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infidelity Results:\n",
      "Noise Scale: 0.1, Categorical Resampling Probability: 0.1, SHAP Infidelity: 0.0898, Shapley Value Sampling Infidelity: 0.0897, DeepLIFT Infidelity: 0.0874\n",
      "Noise Scale: 0.1, Categorical Resampling Probability: 0.5, SHAP Infidelity: 0.0935, Shapley Value Sampling Infidelity: 0.0907, DeepLIFT Infidelity: 0.0930\n",
      "Noise Scale: 0.1, Categorical Resampling Probability: 0.9, SHAP Infidelity: 0.0958, Shapley Value Sampling Infidelity: 0.0902, DeepLIFT Infidelity: 0.0990\n",
      "Noise Scale: 0.5, Categorical Resampling Probability: 0.1, SHAP Infidelity: 0.2124, Shapley Value Sampling Infidelity: 0.1993, DeepLIFT Infidelity: 0.2026\n",
      "Noise Scale: 0.5, Categorical Resampling Probability: 0.5, SHAP Infidelity: 0.2178, Shapley Value Sampling Infidelity: 0.2080, DeepLIFT Infidelity: 0.2101\n",
      "Noise Scale: 0.5, Categorical Resampling Probability: 0.9, SHAP Infidelity: 0.2246, Shapley Value Sampling Infidelity: 0.2215, DeepLIFT Infidelity: 0.2183\n",
      "Noise Scale: 0.9, Categorical Resampling Probability: 0.1, SHAP Infidelity: 0.2598, Shapley Value Sampling Infidelity: 0.2599, DeepLIFT Infidelity: 0.2609\n",
      "Noise Scale: 0.9, Categorical Resampling Probability: 0.5, SHAP Infidelity: 0.2684, Shapley Value Sampling Infidelity: 0.2684, DeepLIFT Infidelity: 0.2672\n",
      "Noise Scale: 0.9, Categorical Resampling Probability: 0.9, SHAP Infidelity: 0.2852, Shapley Value Sampling Infidelity: 0.2788, DeepLIFT Infidelity: 0.2730\n"
     ]
    }
   ],
   "source": [
    "# TODO: Your code and experiments here\n",
    "from captum.metrics import infidelity\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define hyperparameters\n",
    "noise_scales = [0.1, 0.5, 0.9]\n",
    "cat_resample_probas = [0.1, 0.5, 0.9]\n",
    "\n",
    "# Initialize results table\n",
    "results = []\n",
    "\n",
    "x = whole_dataset # input_tensor\n",
    "\n",
    "# Iterate over hyperparameters\n",
    "for noise_scale in noise_scales:\n",
    "    for cat_resample_proba in cat_resample_probas:\n",
    "        # Construct perturbation function\n",
    "        perturb_func = perturb_func_constructor(\n",
    "            noise_scale=noise_scale,\n",
    "            cat_resample_proba=cat_resample_proba,\n",
    "            background_dataset=whole_dataset,\n",
    "            feature_ids=feature_ids,\n",
    "            n_perturb_samples=10\n",
    "        )\n",
    "\n",
    "        # Compute infidelity for each attribution method\n",
    "        infidelity_shap = infidelity(\n",
    "            model,\n",
    "            perturb_func,\n",
    "            x,\n",
    "            attributions=attributions_shap,\n",
    "            normalize=True,\n",
    "            n_perturb_samples=10\n",
    "        ).mean().item()\n",
    "\n",
    "        infidelity_shapley_sampling = infidelity(\n",
    "            model,\n",
    "            perturb_func,\n",
    "            x,\n",
    "            attributions=svs_attribution,\n",
    "            normalize=True,\n",
    "            n_perturb_samples=10\n",
    "        ).mean().item()\n",
    "\n",
    "        infidelity_deeplift = infidelity(\n",
    "            model,\n",
    "            perturb_func,\n",
    "            x,\n",
    "            attributions=deeplift_attribution,\n",
    "            normalize=True,\n",
    "            n_perturb_samples=10\n",
    "        ).mean().item()\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Noise Scale\": noise_scale,\n",
    "            \"Categorical Resampling Probability\": cat_resample_proba,\n",
    "            \"SHAP Infidelity\": infidelity_shap,\n",
    "            \"Shapley Value Sampling Infidelity\": infidelity_shapley_sampling,\n",
    "            \"DeepLIFT Infidelity\": infidelity_deeplift\n",
    "        })\n",
    "\n",
    "# Print results table\n",
    "print(\"Infidelity Results:\")\n",
    "for result in results:\n",
    "    print(f\"Noise Scale: {result['Noise Scale']}, \"\n",
    "          f\"Categorical Resampling Probability: {result['Categorical Resampling Probability']}, \"\n",
    "          f\"SHAP Infidelity: {result['SHAP Infidelity']:.4f}, \"\n",
    "          f\"Shapley Value Sampling Infidelity: {result['Shapley Value Sampling Infidelity']:.4f}, \"\n",
    "          f\"DeepLIFT Infidelity: {result['DeepLIFT Infidelity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611be864-83ac-467c-8925-e5dfa6927463",
   "metadata": {},
   "source": [
    "**Task 2(d)**: Evaluate the computational efficiency of the different methods by taking the following steps: <br />\n",
    "**(i)** Preproccess the [Dry Bean Dataset](https://archive.ics.uci.edu/dataset/602/dry+bean+dataset), similarly to what we have done for Titanic. You can find the description of the different features on the dataset webpage along with the instructions on how to import the data in a Python environment. You do not need to perform any exploratory data analysis for this dataset. <br />\n",
    "**(ii)** Train an additional neural model on the preprocessed data. Briefly report the key performance metrics for the model in your report. <br />\n",
    "**(iii)** Compute the runtimes required to produce the attribution scores for the different methods when considering the first 200 samples in the Titanic and Dry Bean test sets. Report the results in a table in your report. Which methods seem to be the most/least computationally efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d411bc2f-3ece-4352-8e2f-66c771e5916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "dry_bean = fetch_ucirepo(id=602) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = dry_bean.data.features \n",
    "y = dry_bean.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9bb44d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10888\n",
      "Testing dataset size: 2723\n",
      "Features: ['num__Area' 'num__Perimeter' 'num__MajorAxisLength'\n",
      " 'num__MinorAxisLength' 'num__AspectRatio' 'num__Eccentricity'\n",
      " 'num__ConvexArea' 'num__EquivDiameter' 'num__Extent' 'num__Solidity'\n",
      " 'num__Roundness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUNITA\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch the Dry Bean Dataset\n",
    "dry_bean = fetch_ucirepo(id=602)\n",
    "X = dry_bean.data.features\n",
    "y = dry_bean.data.targets\n",
    "\n",
    "X = X.iloc[:, :11]\n",
    "# Convert target labels to numerical values (if necessary)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define the DryBeanDataset class\n",
    "class DryBeanDataset(Dataset):\n",
    "    __create_key = object()\n",
    "\n",
    "    @classmethod\n",
    "    def create_datasets(\n",
    "        cls,\n",
    "        label_name=\"Class\",\n",
    "        split_seed=42,\n",
    "        test_size=0.2,\n",
    "    ):\n",
    "        train_dataset_beans = DryBeanDataset(\n",
    "            cls.__create_key,\n",
    "            label_name=label_name,\n",
    "            split_seed=split_seed,\n",
    "            test_size=test_size,\n",
    "            train=True,\n",
    "        )\n",
    "        test_dataset_beans = DryBeanDataset(\n",
    "            cls.__create_key,\n",
    "            label_name=label_name,\n",
    "            split_seed=split_seed,\n",
    "            test_size=test_size,\n",
    "            train=False,\n",
    "        )\n",
    "        return train_dataset_beans, test_dataset_beans\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        create_key=None,\n",
    "        label_name=\"Class\",\n",
    "        split_seed=42,\n",
    "        test_size=0.2,\n",
    "        train=True,\n",
    "    ):\n",
    "        if create_key != DryBeanDataset.__create_key:\n",
    "            raise ValueError(\n",
    "                \"Illegal initialisation attempt — please use create_datasets to initialise.\"\n",
    "            )\n",
    "\n",
    "        # Split the dataset into train and test\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=split_seed, shuffle=True\n",
    "        )\n",
    "        if train:\n",
    "            self.raw_data = x_train, y_train\n",
    "        else:\n",
    "            self.raw_data = x_test, y_test\n",
    "\n",
    "        # Preprocess the data\n",
    "        x_train_processed, preprocessor = preprocess_train_data(\n",
    "            x_train, scaled_features=X.columns.tolist()\n",
    "        )\n",
    "        x_train = pd.DataFrame(\n",
    "            x_train_processed, columns=preprocessor.get_feature_names_out()\n",
    "        )\n",
    "        x_test_processed = preprocess_test_data(x_test, preprocessor)\n",
    "        x_test = pd.DataFrame(\n",
    "            x_test_processed, columns=preprocessor.get_feature_names_out()\n",
    "        )\n",
    "\n",
    "        # Select data partition and convert to tensors\n",
    "        if train:\n",
    "            samples = x_train\n",
    "            labels = y_train\n",
    "        else:\n",
    "            samples = x_test\n",
    "            labels = y_test\n",
    "        self.samples = torch.tensor(samples.to_numpy(), dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.features = preprocessor.get_feature_names_out()\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]\n",
    "\n",
    "# Preprocessing functions\n",
    "def preprocess_train_data(\n",
    "    df,\n",
    "    scaled_features=None,\n",
    "    categorical_features=None,\n",
    "    scaler=RobustScaler(quantile_range=(10, 90)),\n",
    "):\n",
    "    if scaled_features is None and categorical_features is None:\n",
    "        warnings.warn(\"No features specified for preprocessing, using raw data.\")\n",
    "        scaled_features = []\n",
    "        categorical_features = []\n",
    "    elif scaled_features is None:\n",
    "        scaled_features = [c for c in df.columns if c not in categorical_features]\n",
    "    elif categorical_features is None:\n",
    "        categorical_features = [c for c in df.columns if c not in scaled_features]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", scaler, scaled_features),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    preprocessed_df = preprocessor.fit_transform(df)\n",
    "    return preprocessed_df, preprocessor\n",
    "\n",
    "def preprocess_test_data(df, preprocessor):\n",
    "    preprocessed_df = preprocessor.transform(df)\n",
    "    return preprocessed_df\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset_beans, test_dataset_beans = DryBeanDataset.create_datasets(\n",
    "    test_size=0.2,\n",
    "    split_seed=42,\n",
    ")\n",
    "train_dl_beans = DataLoader(\n",
    "    dataset=train_dataset_beans,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dl_beans = DataLoader(\n",
    "    dataset=test_dataset_beans,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Print dataset details\n",
    "print(\"Training dataset size:\", len(train_dataset_beans))\n",
    "print(\"Testing dataset size:\", len(test_dataset_beans))\n",
    "print(\"Features:\", train_dataset_beans.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8992b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.3548,  0.0000,  ..., -0.0940,  0.0000,  1.0000],\n",
       "        [-0.5000,  0.2581,  0.0000,  ..., -0.0570,  0.0000,  1.0000],\n",
       "        [-1.0000, -0.3226,  0.0000,  ...,  0.9276,  1.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0161,  0.0000,  ...,  0.0228,  0.0000,  1.0000],\n",
       "        [ 0.0000, -0.0645,  0.0000,  ..., -0.0936,  1.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0940,  1.0000,  0.0000]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.samples # To observe the number of samples in train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fcc89acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0659\n",
      "Epoch [2/20], Loss: 0.4969\n",
      "Epoch [3/20], Loss: 0.2944\n",
      "Epoch [4/20], Loss: 0.2082\n",
      "Epoch [5/20], Loss: 0.1716\n",
      "Epoch [6/20], Loss: 0.1532\n",
      "Epoch [7/20], Loss: 0.1428\n",
      "Epoch [8/20], Loss: 0.1363\n",
      "Epoch [9/20], Loss: 0.1320\n",
      "Epoch [10/20], Loss: 0.1288\n",
      "Epoch [11/20], Loss: 0.1264\n",
      "Epoch [12/20], Loss: 0.1246\n",
      "Epoch [13/20], Loss: 0.1231\n",
      "Epoch [14/20], Loss: 0.1219\n",
      "Epoch [15/20], Loss: 0.1209\n",
      "Epoch [16/20], Loss: 0.1199\n",
      "Epoch [17/20], Loss: 0.1191\n",
      "Epoch [18/20], Loss: 0.1185\n",
      "Epoch [19/20], Loss: 0.1180\n",
      "Epoch [20/20], Loss: 0.1176\n",
      "Test Loss: 0.2210\n",
      "Test Accuracy: 92.25%\n",
      "Test F1 Score: 0.9225\n",
      "Test AUC Score: 0.9946\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define the Neural Network Model\n",
    "class DryBeanClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(DryBeanClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = len(train_dataset_beans.features)  # Number of features\n",
    "hidden_size = 64  # Number of neurons in the hidden layer\n",
    "num_classes = 7  # Number of classes in the Dry Bean Dataset\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model_bean = DryBeanClassifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_bean.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for i, (inputs, labels) in enumerate(train_dl_beans):\n",
    "        # Forward pass\n",
    "        outputs = model_bean(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss for every epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_bean.eval()  # Set the model to evaluation mode\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "total_loss = 0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl_beans:\n",
    "        outputs = model_bean(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        _, preds = torch.max(outputs, 1)  # Get the predicted class\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "avg_loss = total_loss / num_batches\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "# Compute AUC (only if num_classes > 2)\n",
    "if num_classes > 2:\n",
    "    auc = roc_auc_score(all_labels, all_probs, multi_class=\"ovr\")\n",
    "else:\n",
    "    auc = roc_auc_score(all_labels, [p[1] for p in all_probs])  # Binary case\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test AUC Score: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUNITA\\anaconda3\\lib\\site-packages\\captum\\_utils\\gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUNITA\\anaconda3\\lib\\site-packages\\captum\\attr\\_core\\deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# Define a function to measure the runtime of a method\n",
    "\n",
    "def measure_runtime(method, *args, **kwargs):\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    # Execute the method with the given arguments\n",
    "    result = method(*args, **kwargs)\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "    # Return the result and the time it took to execute the method\n",
    "    return result, end_time - start_time\n",
    "\n",
    "# Select subsets of the Titanic dataset (200 samples for selected and the rest for background)\n",
    "selected_samples_titanic = test_dataset.samples[:200]\n",
    "background_samples_titanic = test_dataset.samples[200:]\n",
    "\n",
    "# Select subsets of the Bean dataset (200 samples for selected and the rest for background)\n",
    "selected_samples_bean = test_dataset_beans.samples[:200]\n",
    "background_samples_beans = test_dataset_beans.samples[200:]\n",
    "\n",
    "# Define the feature IDs to be used for attributions \n",
    "feature_ids = [0, 1, 2, 3, 4, 5, 5]\n",
    "\n",
    "# Create a feature mask tensor that will be passed to the methods, with the specified features\n",
    "feature_mask = torch.tensor([[0, 1, 2, 3, 4, 5, 5]]).to(DEVICE)\n",
    "\n",
    "# Initialize a baseline tensor for the Titanic dataset, with all values set to zero\n",
    "baseline_titanic = torch.zeros_like(selected_samples_titanic)\n",
    "\n",
    "# Compute runtimes and attributions for each method on the Titanic dataset\n",
    "# 1. SHAP method\n",
    "shap_titanic, shap_time_titanic = measure_runtime(shap_attribute, model, selected_samples_titanic, background_samples_titanic, feature_ids)\n",
    "\n",
    "# 2. SVS method using Captum's attribute function\n",
    "svs_titanic, svs_time_titanic = measure_runtime(svs.attribute, selected_samples_titanic, target=0, feature_mask=feature_mask, baselines=baseline_titanic)\n",
    "\n",
    "# 3. DeepLIFT method using Captum's attribute function\n",
    "dl_titanic, dl_time_titanic = measure_runtime(deep_lift.attribute, selected_samples_titanic, target=0, baselines=baseline_titanic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ca539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature IDs to be used for attribution (from 0 to 10 for 11 features)\n",
    "feature_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Convert feature_ids into a tensor and move it to the specified device (e.g., GPU or CPU)\n",
    "feature_mask = torch.tensor([feature_ids]).to(DEVICE)\n",
    "\n",
    "# Initialize a baseline tensor for the Bean dataset, with all values set to zero\n",
    "baseline_beans = torch.zeros_like(selected_samples_bean)\n",
    "\n",
    "# Initialize Shapley Value Sampling (SVS) method for the Bean model\n",
    "svs1 = ShapleyValueSampling(model_bean)\n",
    "\n",
    "# Initialize DeepLift method for the Bean model\n",
    "deep_lift1 = DeepLift(model_bean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4c89575",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_beans, shap_time_beans = measure_runtime(shap_attribute, model_bean, selected_samples_bean, background_samples_beans, feature_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ceaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "svs_bean, svs_time_bean= measure_runtime(svs1.attribute, selected_samples_bean, target=0, feature_mask=feature_mask, baselines=baseline_beans)\n",
    "dl_bean, dl_time_bean = measure_runtime(deep_lift1.attribute, selected_samples_bean, target=0, baselines=baseline_beans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Method  Titanic Runtime (s)  Dry Bean Runtime (s)\n",
      "0      SHAP           108.801288            800.770918\n",
      "1       SVS             0.096668              0.139512\n",
      "2  DeepLift             0.009530              0.007002\n"
     ]
    }
   ],
   "source": [
    "# Create a table of results\n",
    "\n",
    "results = {\n",
    "    \"Method\": [\"SHAP\", \"SVS\", \"DeepLift\"],\n",
    "    \"Titanic Runtime (s)\": [shap_time_titanic, svs_time_titanic, dl_time_titanic],\n",
    "    \"Dry Bean Runtime (s)\": [shap_time_beans, svs_time_bean, dl_time_bean],\n",
    "}\n",
    "\n",
    "# Print the table\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec783c-e350-473e-b3e1-140095ebed53",
   "metadata": {},
   "source": [
    "## Counterfactual Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb92884-22cd-46e4-824d-8354e35ce856",
   "metadata": {},
   "source": [
    "### Designing a Distance Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f2aac-ad49-4a47-a74a-21158879f06d",
   "metadata": {},
   "source": [
    "**Task 3(a)**: First, we need to specify a suitable distance metric for measuring the closeness between the points. Depending on the dataset, one could choose the standard distance functions like the Manhattan (L1) distance, Euclidean (L2) distance, and more specialised ones like Gower distance for better handling datasets with both categorical and continuous dataset. However, the design of distance metric can be very flexible. For example, the standard L1 distance is (k is the number of features) $$d_{L1}(x, x') = \\sum_{i}^{k} |x_i-x'_i|$$\n",
    "\n",
    "If the features have different value ranges, we could normalise the L1 distance with the maximum and minimum values of each feature (indexed $i$) in the training dataset, $max_i$, $min_i$ : $$d_{L1, normalised}(x, x') = \\sum_{i}^{k} |(x_i-x'_i)/(max_i-min_i)|$$\n",
    "\n",
    "On top of this, we could also add customised weighting factors $\\mathbf{w}=w_1, ..., w_k$ to capture the importance of each feature, and the weighted L1 distance is: $$d_{L1, normalised, weighted}(x, x') = \\sum_{i}^{k} w_i|(x_i-x'_i)/(max_i-min_i)|$$\n",
    "\n",
    "Given the background above, we want to design a distance function for the preprocessed version of our Titanic dataset. Explore the dataset characteristics and answer the following questions:\n",
    "**a)** Briefly discuss the weighting of each input variable in the preprocessed dataset, if we use standard L1 and normalised L1?\n",
    "**b)** If we want to treat each feature equally in the original unprocessed dataset, how would you design the distance metric for the preprocessed dataset using L1-based distance? Write down the detail of your distance function for the preprocessed dataset and justify why each original feature is treated equally.\n",
    "**c)** Implement your distance function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc535906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1309, 7])\n",
      "tensor([[ 0.0000, -0.3548,  0.0000,  ..., -0.0940,  0.0000,  1.0000],\n",
      "        [-0.5000,  0.2581,  0.0000,  ..., -0.0570,  0.0000,  1.0000],\n",
      "        [-1.0000, -0.3226,  0.0000,  ...,  0.9276,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.2258,  0.0000,  ..., -0.0975,  1.0000,  0.0000],\n",
      "        [-1.0000,  0.7097,  1.0000,  ...,  2.8049,  0.0000,  1.0000],\n",
      "        [-1.0000, -0.1290,  0.0000,  ...,  0.4984,  1.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "train_dataset.samples[:10]\n",
    "print(whole_dataset.shape)  # Check the combined shape\n",
    "print(whole_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3fd9846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranges:\n",
      "Feature 0: Min = -1.0, Max = 0.0\n",
      "Feature 1: Min = -0.89784836769104, Max = 1.6774193048477173\n",
      "Feature 2: Min = 0.0, Max = 8.0\n",
      "Feature 3: Min = 0.0, Max = 4.5\n",
      "Feature 4: Min = -0.20644983649253845, Max = 7.088052272796631\n",
      "Feature 5: Min = 0.0, Max = 1.0\n",
      "Feature 6: Min = 0.0, Max = 1.0\n",
      "[(-1.0, 0.0), (-0.89784836769104, 1.6774193048477173), (0.0, 8.0), (0.0, 4.5), (-0.20644983649253845, 7.088052272796631), (0.0, 1.0), (0.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "def calculate_feature_ranges(dataset):\n",
    "    \"\"\"\n",
    "    Calculates the minimum and maximum values for each feature in a dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (Tensor): A 2D tensor where each row represents a data point\n",
    "                          and each column represents a feature.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: A list where each element is a tuple (min, max) representing\n",
    "                        the range for the corresponding feature.  Returns None if\n",
    "                        the dataset is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset.numel() == 0:  # Check if the dataset is empty\n",
    "        return None\n",
    "\n",
    "    num_features = dataset.shape[1]\n",
    "    feature_ranges = []\n",
    "\n",
    "    for i in range(num_features):\n",
    "        min_val = torch.min(dataset[:, i])  # Minimum value of the i-th feature\n",
    "        max_val = torch.max(dataset[:, i])  # Maximum value of the i-th feature\n",
    "        feature_ranges.append((min_val.item(), max_val.item())) # .item() to get the numerical value\n",
    "\n",
    "    return feature_ranges\n",
    "\n",
    "\n",
    "# Example Usage (assuming 'whole_dataset' is your tensor):\n",
    "feature_ranges = calculate_feature_ranges(whole_dataset)\n",
    "\n",
    "if feature_ranges:\n",
    "    print(\"Feature Ranges:\")\n",
    "    for i, (min_val, max_val) in enumerate(feature_ranges):\n",
    "        print(f\"Feature {i}: Min = {min_val}, Max = {max_val}\")\n",
    "\n",
    "print(feature_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b077fa1-b082-438a-806b-119714ca33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3748)\n"
     ]
    }
   ],
   "source": [
    "def distance_function(x1, x2, feature_ranges):\n",
    "    \"\"\"\n",
    "    Your distance function with weighted features.\n",
    "\n",
    "    Args:\n",
    "        x1 (Tensor): A 1-d array of shape (k,)\n",
    "        x2 (Tensor): A 1-d array of shape (k,)\n",
    "        feature_ranges (list or tuple of tuples): Min/max ranges for each feature.\n",
    "\n",
    "    Returns:\n",
    "        distance (float): A real number >= 0\n",
    "    \"\"\"\n",
    "\n",
    "    if len(x1) != len(x2) or len(x1) != len(feature_ranges):\n",
    "        raise ValueError(\"Input tensors and feature ranges must have the same length.\")\n",
    "\n",
    "    distance = 0\n",
    "    for i in range(len(x1)):\n",
    "        min_val, max_val = feature_ranges[i]\n",
    "\n",
    "        normalized_diff = abs(x1[i] - x2[i]) / (max_val - min_val) if max_val != min_val else abs(x1[i] - x2[i])\n",
    "        \n",
    "        weight = 1.0  # Default weight\n",
    "        if i >= len(x1) - 2:  # Last two features\n",
    "            weight = 0.5\n",
    "\n",
    "        distance += weight * normalized_diff\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "x1 = whole_dataset[0]\n",
    "x2 = whole_dataset[2]\n",
    "\n",
    "distance = distance_function(x1, x2, feature_ranges)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df345ad0-6bdb-47b9-abf9-598c23a963c4",
   "metadata": {},
   "source": [
    "### Nearest-Neighbour Counterfactual Explanations (NNCE)\n",
    "\n",
    "**Task 3(b)**: As introduced in the tutorial, NNCEs are a simple yet effective method for finding counterfactuals. Implement the NNCE functions.\n",
    "\n",
    "Instructions:\n",
    "1. determine desired label for the counterfactual\n",
    "2. find the dataset points with desired label as predicted by the model\n",
    "3. find the point with the minimum distance and return it as NNCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47409a30-fbad-4371-99d6-b87d30cd6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nnce(x, m, train_set, dist):\n",
    "    \"\"\"\n",
    "    Function to compute NNCE.\n",
    "\n",
    "    Parameters:\n",
    "        x (Tensor): Input, a 1-d array of shape (k,)\n",
    "        m (Sequential): Our neural network\n",
    "        train_set (TitanicDataset): Our Titanic dataset\n",
    "        dist (function): Your previously implemented distance function\n",
    "\n",
    "    Returns:\n",
    "        nnce (Tensor): Nearest neighbour counterfactual explanation, an 1-d array of shape (k,)\n",
    "    \"\"\"\n",
    "    # Step 1: Determine the predicted label for the input instance\n",
    "    m.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        pred = m(x.unsqueeze(0))  # Add batch dimension\n",
    "        pred_label = (pred > 0.5).int().item()  # Convert probability to binary label\n",
    "\n",
    "    # Step 2: Find candidate counterfactuals with the opposite label\n",
    "    candidates = []\n",
    "    for i in range(len(train_set)):\n",
    "        x_i, y_i = train_set[i]  # Get the i-th sample from the training set\n",
    "        with torch.no_grad():\n",
    "            pred_i = m(x_i.unsqueeze(0))  # Predict label for the candidate\n",
    "            pred_label_i = (pred_i > 0.5).int().item()  # Convert probability to binary label\n",
    "\n",
    "        # If the candidate has the opposite label, add it to the list\n",
    "        if pred_label_i != pred_label:\n",
    "            d = dist(x, x_i, feature_ranges)  # Compute distance to the input instance\n",
    "            candidates.append((x_i, d))  # Store the candidate and its distance\n",
    "\n",
    "    # Step 3: Find the candidate with the minimum distance\n",
    "    if not candidates:\n",
    "        raise ValueError(\"No counterfactual found in the training set.\")\n",
    "\n",
    "    # Sort candidates by distance and select the nearest one\n",
    "    candidates.sort(key=lambda x: x[1])  # Sort by distance\n",
    "    nnce = candidates[0][0]  # Select the nearest counterfactual\n",
    "\n",
    "    return nnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07e25d4e-eb20-4a62-a468-64ce6834d6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0082], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.6953], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# use this code block to test if your function is working\n",
    "# first print out the original input's prediction result\n",
    "test_input = test_dataset.samples.to(DEVICE)[0]\n",
    "print(model(test_input))\n",
    "\n",
    "# now compute NNCE and print out the NNCE's prediction result. Ideally this is different from the result for the original input.\n",
    "nnce = compute_nnce(test_input, model, train_set=train_dataset, dist=distance_function)\n",
    "print(model(nnce))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6290a-7c2b-4064-8ed0-3a4056bac9dc",
   "metadata": {},
   "source": [
    "### Gradient-Based Counterfactual Explanations\n",
    "\n",
    "**Task 3(c)**: Complete the PyTorch implementation for the gradient-based method in [Wachter et al. 2017]: WAC.\n",
    "\n",
    "Instructions:\n",
    "1. We are going to optimise the following loss function to find a counterfactual x': $  argmin_{x'} \\text{ } BCE(y', (1-y)) + \\lambda cost(x, x')$, where $BCE$ is binary cross entropy loss, $y'$ is the predicted label of $x'$, $y$ is the predicted label of $x$, $cost(,)$ is your chosen distance function in Task 1, and $\\lambda$ is the trade-off parameter between validity and proximity. First, implement your chosen distance metric in ```CostLoss.forward()```\n",
    "2. Follow the code structure in the ```compute_wac()``` function, complete the implementation.\n",
    "    2.1. specify the target label for the counterfactual\n",
    "    2.2. implement gradient descent procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee23134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.0, 0.0),\n",
       " (-0.89784836769104, 1.6774193048477173),\n",
       " (0.0, 8.0),\n",
       " (0.0, 4.5),\n",
       " (-0.20644983649253845, 7.088052272796631),\n",
       " (0.0, 1.0),\n",
       " (0.0, 1.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ranges # Print the min and max values for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa6aae81-d6bb-4037-810d-198c00143334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CostLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(CostLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        The PyTorch version of your distance function\n",
    "\n",
    "        Parameters:\n",
    "            x1 (Tensor): A 1-d array of shape (k,)\n",
    "            x2 (Tensor): A 1-d array of shape (k,)\n",
    "\n",
    "        Returns:\n",
    "            distance (Tensor): a real number\n",
    "        \"\"\"\n",
    "        # TODO: Here is an example of standard L1 loss, replace it with your designed distance function in Task 1\n",
    "        dist = distance_function(x1, x2, feature_ranges)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ae1f7-8c47-4a71-a817-2f22d48a64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import datetime\n",
    "\n",
    "def compute_wac(x, m, lamb=0.1, lr=0.01, max_iter=1000, max_allowed_minutes=0.5):\n",
    "    \"\"\"\n",
    "    Function to find WAC using gradient descent.\n",
    "\n",
    "    Parameters:\n",
    "        x (Tensor): Input x, an 1-d array of shape (k,)\n",
    "        m (Sequential): PyTorch model\n",
    "        lamb (float): Lambda, the tradeoff term in the loss function\n",
    "        lr (float): Learning rate for gradient descent\n",
    "        max_iter (int): maximum allowed iteration\n",
    "        max_allowed_minutes (float): maximum allowed minutes\n",
    "\n",
    "    Returns:\n",
    "        counterfactual (Tensor): Counterfactual point, an 1-d array of shape (k,)\n",
    "    \"\"\"\n",
    "    # initialise the counterfactual search at the input point\n",
    "    x = x.to(DEVICE)\n",
    "    wac = Variable(x.clone(), requires_grad=True).to(DEVICE)\n",
    "\n",
    "    # initialise an optimiser for gradient descent over the wac counterfactual point\n",
    "    optimiser = Adam([wac], lr, amsgrad=True)\n",
    "\n",
    "    # instantiate the two components of the loss function\n",
    "    validity_loss = torch.nn.BCELoss()\n",
    "    cost_loss = CostLoss()\n",
    "\n",
    "    # TASK: specify target label y: either 0 or 1, depending on the original prediction\n",
    "    # TODO: Start your code here\n",
    "    m.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        pred = m(x.unsqueeze(0))  # Add batch dimension\n",
    "        pred_label = (pred > 0.5).int().item()  # Convert probability to binary label\n",
    "        y_target = torch.Tensor([1 - pred_label]).to(DEVICE)  # Opposite label\n",
    "\n",
    "\n",
    "    # the total loss in the instructions: loss = validity_loss + lamb * cost_loss\n",
    "    # TODO: End your code here\n",
    "\n",
    "    # Compute class probability\n",
    "    class_prob = m(wac)\n",
    "    wac_valid = False\n",
    "    iterations = 0\n",
    "\n",
    "    # Set maximum allowed time for computing 1 counterfactual\n",
    "    t0 = datetime.datetime.now()\n",
    "    t_max = datetime.timedelta(minutes=max_allowed_minutes)\n",
    "\n",
    "    # Start gradient descent\n",
    "    while not wac_valid and iterations <= max_iter:\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Compute the predicted label for the current counterfactual\n",
    "        class_prob = m(wac)\n",
    "\n",
    "        # Compute the validity loss (binary cross-entropy)\n",
    "        validity = validity_loss(class_prob, y_target)\n",
    "\n",
    "        # Compute the cost loss (distance to the original input)\n",
    "        cost = cost_loss.forward(wac, x)\n",
    "\n",
    "        # Compute the total loss\n",
    "        loss = validity + lamb * cost\n",
    "\n",
    "        # Perform gradient descent\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        # Check if the counterfactual is valid\n",
    "        if y_target == 0 and class_prob < 0.5 or y_target == 1 and class_prob >= 0.5:\n",
    "            wac_valid = True\n",
    "\n",
    "        # Break if the maximum allowed time is exceeded\n",
    "        if datetime.datetime.now() - t0 > t_max:\n",
    "            break\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return wac    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3730ddc2-6dbe-46a2-8bf3-e833800c52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0141], grad_fn=<SigmoidBackward0>)\n",
      "explainantion tensor([ 0.0824, -0.1583,  1.0694,  0.4331,  0.0700,  0.0300,  0.9164],\n",
      "       requires_grad=True)\n",
      "tensor([0.7658], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# use this code block to test if your function is working\n",
    "# first print out the original input's prediction result\n",
    "test_input = test_dataset.samples.to(DEVICE)[1]\n",
    "print(model(test_input))\n",
    "\n",
    "# now compute WAC and print out the WAC's prediction result. Ideally this is different from the result for the original input.\n",
    "nnce = compute_wac(test_input, model)\n",
    "print(\"explainantion\", nnce)\n",
    "print(model(nnce))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7d395-b999-4100-85dd-7b5eed5c57d7",
   "metadata": {},
   "source": [
    "### Performance of the Two Methods\n",
    "\n",
    "**Task 3(d)**: In order to understand better how these two methods compare, we use the following metrics to quantitatively evaluate each of the methods:\n",
    "- Validity: percentage of the counterfactuals that are valid.\n",
    "- Proximity: average distance between the counterfactuals and the inputs. Smaller distance (lower cost) indicates better proximity.\n",
    "- Plausibility: average distance of a counterfactual to its 5 nearest neighbours in the training dataset, further averaged over all counterfactuals. The closer it is to the nearest neighbours, the more plausible. Consider this metric as a simplified version of Local Outlier Factor.\n",
    "\n",
    "For each counterfactual method, we randomly select 20 test inputs, generate counterfactuals for them, and compare the average performances for each of the metrics.\n",
    "We repeat this process for 5 times and calculate the mean and standard deviation of each metrics. We have provided code for these experiments. Complete the following codes for calculating the evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4847e8d0-c76c-462d-a986-ccd2dc300e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_three_metrics_for_group_of_inputs(inputs, m, counterfactuals, train_set, dist):\n",
    "    validity, proximity, plausibility = 0, 0, 0\n",
    "    # examine validity, proximity, plausibility for each input-counterfactual pair\n",
    "    for i, x in enumerate(inputs):\n",
    "        ce = counterfactuals[i]\n",
    "\n",
    "        this_val = calculate_validity(x, ce, m)\n",
    "        this_prox = calculate_proximity(x, ce, dist)\n",
    "        this_plaus = calculate_plausibility(ce, train_set, dist)\n",
    "\n",
    "        validity += this_val\n",
    "        proximity += this_prox\n",
    "        plausibility += this_plaus\n",
    "\n",
    "    # average evaluation metrics over all the test inputs\n",
    "    validity = validity / len(inputs)\n",
    "    proximity = proximity / len(inputs)\n",
    "    plausibility = plausibility / len(inputs)\n",
    "    return validity, proximity, plausibility\n",
    "\n",
    "\n",
    "# TASK: for each input-counterfactual pair, calculate validity, proximity, and plausibility\n",
    "\n",
    "# check whether a counterfactual ce is valid or not\n",
    "def calculate_validity(x, ce, m):\n",
    "    \"\"\"\n",
    "    Check whether a counterfactual is valid.\n",
    "\n",
    "    Parameters:\n",
    "        x (Tensor): Input, a 1-d array of shape (k,)\n",
    "        ce (Tensor): Counterfactual, a 1-d array of shape (k,)\n",
    "        m (Sequential): PyTorch model\n",
    "\n",
    "    Returns:\n",
    "        validity (int): 1 if valid, 0 otherwise\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "    m.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        pred_x = m(x.unsqueeze(0))  # Predict label for the input\n",
    "        pred_ce = m(ce.unsqueeze(0))  # Predict label for the counterfactual\n",
    "\n",
    "        # Convert probabilities to binary labels\n",
    "        label_x = (pred_x > 0.5).int().item()\n",
    "        label_ce = (pred_ce > 0.5).int().item()\n",
    "\n",
    "        # Check if the counterfactual has the opposite label\n",
    "        if label_ce != label_x:\n",
    "            return 1  # Valid\n",
    "        else:\n",
    "            return 0  # Invalid   \n",
    "    \n",
    "\n",
    "# check the distance between a counterfactual and the input\n",
    "def calculate_proximity(x, ce, dist):\n",
    "    \"\"\"\n",
    "    Calculate the distance between the input and the counterfactual.\n",
    "\n",
    "    Parameters:\n",
    "        x (Tensor): Input, a 1-d array of shape (k,)\n",
    "        ce (Tensor): Counterfactual, a 1-d array of shape (k,)\n",
    "        dist (function): Distance function\n",
    "\n",
    "    Returns:\n",
    "        proximity (float): Distance between x and ce\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "\n",
    "    return dist(x, ce, feature_ranges).item()\n",
    "\n",
    "# calculate plausibility of a counterfactual\n",
    "def calculate_plausibility(ce, train_set, dist):\n",
    "    \"\"\"\n",
    "    Calculate the plausibility of a counterfactual.\n",
    "\n",
    "    Parameters:\n",
    "        ce (Tensor): Counterfactual, a 1-d array of shape (k,)\n",
    "        train_set (TitanicDataset): Training dataset\n",
    "        dist (function): Distance function\n",
    "\n",
    "    Returns:\n",
    "        plausibility (float): Average distance to 5 nearest neighbours\n",
    "    \"\"\"\n",
    "\n",
    "    # here, calculate the average distance between the counterfactual and its 5 nearest neighbours in the training dataset\n",
    "    \n",
    "    # TODO: Your code here\n",
    "    distances = []\n",
    "    for i in range(len(train_set)):\n",
    "        x_i, _ = train_set[i]  # Get the i-th sample from the training set\n",
    "        d = dist(ce, x_i, feature_ranges)  # Compute distance to the counterfactual\n",
    "        distances.append((x_i, d.item()))\n",
    "\n",
    "    # Sort by distance and select the 5 nearest neighbours\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    nearest_neighbours = distances[:5]\n",
    "\n",
    "    # Calculate the average distance to the 5 nearest neighbours\n",
    "    avg_distance = sum(d for _, d in nearest_neighbours) / 5\n",
    "    return avg_distance    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1cb9d3-cb0b-4473-b7d2-166e76032c61",
   "metadata": {},
   "source": [
    "Now we set up the experiments, compute counterfactuals using NNCE and WAC, then evaluate and compare their performances. Note that depending on your machine, the computation for ```compute_wac()``` could potentially be slow. You can also manually change the function's hyperparameters ```lamb=0.1, lr=0.01, max_iter=1000``` to try and see if WAC could give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d10f578-a107-4fc5-8a33-246018d9b6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683f70777c3d4413a446895824918711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e3f25e9a01471188944d6dd09e5043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad18c025b124e33adefa5085e752e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65610c6943a451aa6c94617099c0061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4759d842a44327a902054c61601579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357a2a7ca72f4c938d4e1fefcd85d0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f96a6e61334914a8e303894c59c436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecf27f89e51447da9ed3d5c9ca3a103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba6bcad0d9340b3b72029d6511afdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123bf85c6f3443e69abe330c8ab0342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf84beb8f26e4c80b18dfd664be3a2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+----------------+\n",
      "| method   | validity      | cost          | plausibility   |\n",
      "+==========+===============+===============+================+\n",
      "| NNCE     | 1.0 +- 0.0    | 0.137 +- 0.02 | 0.035 +- 0.004 |\n",
      "| WAC      | 0.85 +- 0.095 | 0.14 +- 0.037 | 0.17 +- 0.032  |\n",
      "+----------+---------------+---------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "# we store the evaluation results of the five runs in lists\n",
    "nnce_validity, nnce_proximity, nnce_plausibility = [], [], []\n",
    "wac_validity, wac_proximity, wac_plausibility = [], [], []\n",
    "seed_num = 1000\n",
    "\n",
    "# repeat over 5 runs to obtain more robust evaluations\n",
    "for one_run in tqdm(range(5)):\n",
    "    # randomly select 20 test inputs\n",
    "    np.random.seed(seed_num)\n",
    "    test_inputs = test_dataset.samples[np.random.choice(range(len(test_dataset.samples)), 20)]\n",
    "    nnce_counterfactuals, wac_counterfactuals = [], []\n",
    "    # generate counterfactuals\n",
    "    with tqdm(total=1, position=0, leave=True) as pbar:\n",
    "        for x in tqdm(test_inputs, position=0, leave=True):\n",
    "            nnce_counterfactuals.append(compute_nnce(x, model, train_dataset, distance_function))\n",
    "            wac_counterfactuals.append(compute_wac(x, model, lamb=0.1))\n",
    "            pbar.update()\n",
    "\n",
    "    # evaluate counterfactuals\n",
    "    nnvalidity, nnproximity, nnplausibility = calculate_three_metrics_for_group_of_inputs(test_inputs, model,\n",
    "                                                                                          nnce_counterfactuals,\n",
    "                                                                                          train_dataset,\n",
    "                                                                                          distance_function)\n",
    "    nnce_validity.append(nnvalidity)\n",
    "    nnce_proximity.append(nnproximity)\n",
    "    nnce_plausibility.append(nnplausibility)\n",
    "\n",
    "    wvalidity, wproximity, wplausibility = calculate_three_metrics_for_group_of_inputs(test_inputs, model,\n",
    "                                                                                       wac_counterfactuals,\n",
    "                                                                                       train_dataset, distance_function)\n",
    "    wac_validity.append(wvalidity)\n",
    "    wac_proximity.append(wproximity)\n",
    "    wac_plausibility.append(wplausibility)\n",
    "\n",
    "    seed_num += 10\n",
    "\n",
    "# now print out the results\n",
    "from tabulate import tabulate\n",
    "\n",
    "score_names = [\"method\", \"validity\", \"cost\", \"plausibility\"]\n",
    "score_table = [score_names,\n",
    "               [\"NNCE\", f\"{np.mean(nnce_validity).round(3)} +- {np.std(nnce_validity).round(3)}\",\n",
    "                f\"{np.mean(nnce_proximity).round(3)} +- {np.std(nnce_proximity).round(3)}\",\n",
    "                f\"{np.mean(nnce_plausibility).round(3)} +- {np.std(nnce_plausibility).round(3)}\"],\n",
    "               [\"WAC\", f\"{np.mean(wac_validity).round(3)} +- {np.std(wac_validity).round(3)}\",\n",
    "                f\"{np.mean(wac_proximity).round(3)} +- {np.std(wac_proximity).round(3)}\",\n",
    "                f\"{np.mean(wac_plausibility).round(3)} +- {np.std(wac_plausibility).round(3)}\"]]\n",
    "print(tabulate(score_table, headers='firstrow', tablefmt='outline'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474358c-0c66-444a-b528-d4e99f1d4e78",
   "metadata": {},
   "source": [
    "### Performance Differences\n",
    "\n",
    "**Task 3(e)**: Discuss in your report commenting their performance based on the metrics. Link the findings to their theories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51359d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnce [tensor([-0.5000,  0.1935,  0.0000,  0.0000, -0.0214,  0.0000,  1.0000]), tensor([-1.0000,  0.2581,  0.0000,  0.0000,  0.2446,  1.0000,  0.0000]), tensor([-0.5000, -0.0645,  1.0000,  0.5000,  0.2064,  0.0000,  1.0000]), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5979, 0.0000, 1.0000]), tensor([ 0.0000, -0.1290,  0.0000,  0.0000, -0.0961,  1.0000,  0.0000]), tensor([ 0.0000, -0.0968,  1.0000,  0.0000, -0.0958,  0.0000,  1.0000]), tensor([-1.0000,  0.2581,  0.0000,  0.0000,  0.2446,  1.0000,  0.0000]), tensor([0.0000, 0.0000, 1.0000, 0.5000, 0.0106, 0.0000, 1.0000]), tensor([ 0.0000, -0.1290,  0.0000,  0.0000, -0.0961,  1.0000,  0.0000]), tensor([-1.0000,  0.1613,  0.0000,  0.0000,  0.1716,  0.0000,  1.0000]), tensor([ 0.0000, -0.4516,  0.0000,  0.0000, -0.0751,  0.0000,  1.0000]), tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -0.0965,  1.0000,  0.0000]), tensor([-0.5000, -0.3226,  1.0000,  0.5000, -0.0214,  1.0000,  0.0000]), tensor([ 0.0000,  0.2903,  0.0000,  0.0000, -0.0699,  1.0000,  0.0000]), tensor([ 0.0000, -0.8790,  1.0000,  0.5000, -0.0103,  0.0000,  1.0000]), tensor([-1.0000,  0.2581,  0.0000,  0.0000,  0.2446,  1.0000,  0.0000]), tensor([-1.0000,  0.2581,  0.0000,  0.0000,  0.2446,  1.0000,  0.0000]), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5979, 0.0000, 1.0000]), tensor([-1.0000,  0.2581,  0.0000,  0.0000,  0.2446,  1.0000,  0.0000]), tensor([ 0.0000, -0.3871,  0.0000,  0.0000, -0.0961,  1.0000,  0.0000])]\n",
      "wac [tensor([-0.4534,  1.1751, -0.0783, -0.0724,  0.0180,  0.0783,  0.9213],\n",
      "       requires_grad=True), tensor([-1.0000,  0.0000,  0.0000,  0.0000,  0.9212,  1.0000,  0.0000],\n",
      "       requires_grad=True), tensor([-0.5227, -0.1551,  2.0431,  0.5135, -0.0705,  0.0607,  0.9121],\n",
      "       requires_grad=True), tensor([ 0.0369,  0.0491,  0.0116,  0.0478, -0.0566,  0.0424,  0.9542],\n",
      "       requires_grad=True), tensor([ 0.0174, -0.1433,  0.0178, -0.0180, -0.0807,  1.0185,  0.0175],\n",
      "       requires_grad=True), tensor([ 3.9199e-02, -8.9786e-02,  2.1461e-04, -4.8793e-03, -1.0347e-01,\n",
      "         3.0647e-02,  1.0243e+00], requires_grad=True), tensor([-1.0000,  0.3548,  1.0000,  0.5000,  0.9776,  1.0000,  0.0000],\n",
      "       requires_grad=True), tensor([ 0.0824, -0.1583,  1.0694,  0.4331,  0.0700,  0.0300,  0.9164],\n",
      "       requires_grad=True), tensor([ 0.0172, -0.1436,  0.0176, -0.0178, -0.0757,  1.0182,  0.0173],\n",
      "       requires_grad=True), tensor([-1.0276,  0.1980, -0.0243, -0.0280,  0.1407, -0.0284,  1.0277],\n",
      "       requires_grad=True), tensor([ 0.0669, -0.1693,  0.0747,  0.0257, -0.1025,  0.0644,  0.9893],\n",
      "       requires_grad=True), tensor([ 0.0196,  0.0199, -0.0186, -0.0195, -0.0843,  1.0192, -0.0172],\n",
      "       requires_grad=True), tensor([-0.5000, -0.8065,  1.0000,  1.0000,  0.3856,  1.0000,  0.0000],\n",
      "       requires_grad=True), tensor([ 0.0181,  0.2725,  0.0180,  0.0171, -0.0779,  1.0180,  0.0180],\n",
      "       requires_grad=True), tensor([ 0.0729, -0.7936,  1.0696,  1.0749,  0.0113,  0.0642,  1.0757],\n",
      "       requires_grad=True), tensor([-1.0000,  0.2903,  1.0000,  0.0000,  1.0750,  1.0000,  0.0000],\n",
      "       requires_grad=True), tensor([-1.0000,  0.1613,  1.0000,  0.0000,  0.5496,  1.0000,  0.0000],\n",
      "       requires_grad=True), tensor([ 0.0369,  0.0491,  0.0116,  0.0478, -0.0566,  0.0424,  0.9542],\n",
      "       requires_grad=True), tensor([-1.0000,  0.4194,  0.0000,  0.0000,  1.7086,  1.0000,  0.0000],\n",
      "       requires_grad=True), tensor([-0.0382, -0.3568, -0.0328, -0.0115, -0.0570,  1.0355,  0.0384],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(\"nnce\", nnce_counterfactuals)\n",
    "print(\"wac\", wac_counterfactuals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
